{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50078d2a-d6f1-4d25-90fd-c9a0c15e31dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q1. What is Bayes' theorem?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebcf739d-d93a-456f-aea8-3dba94d333aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Bayes' theorem is a mathematical formula used to determine the probability of an event occurring, given some prior knowledge or evidence. It is named after the 18th-century English statistician and Presbyterian minister Thomas Bayes. The theorem can be stated as:\n",
    "\n",
    "P(A|B) = P(B|A) * P(A) / P(B)\n",
    "\n",
    "where P(A|B) is the conditional probability of event A occurring given that event B has occurred, P(B|A) is the conditional probability of event B given that event A has occurred, P(A) is the prior probability of event A occurring, and P(B) is the prior probability of event B occurring.\n",
    "\n",
    "Bayes' theorem is widely used in many fields, including statistics, machine learning, natural language processing, and artificial intelligence. It forms the basis of Bayesian statistics, which is a framework for updating beliefs and making predictions based on new data.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75ff7ed0-85df-4b1b-934b-370ad8c2a979",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q2. What is the formula for Bayes' theorem?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f6e054e-88c5-439d-8ac0-7177fdfcb91b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Bayes' theorem is a mathematical formula for calculating conditional probabilities. It states that the probability of an event occurring based on prior knowledge of related events can be calculated using the following formula:\n",
    "\n",
    "P(A|B) = P(B|A) * P(A) / P(B)\n",
    "\n",
    "where:\n",
    "\n",
    "P(A|B) is the probability of event A occurring given that event B has occurred.\n",
    "P(B|A) is the probability of event B occurring given that event A has occurred.\n",
    "P(A) is the prior probability of event A.\n",
    "P(B) is the prior probability of event B.\n",
    "In other words, Bayes' theorem calculates the probability of an event A occurring given some observed evidence B, by taking into account the prior probability of A and the likelihood of B given A.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "032b9a7b-b192-4e53-8d80-df0dc6ae302c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q3. How is Bayes' theorem used in practice?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c97ec02a-e0dc-462f-b086-19c645fa3fe9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Machine learning: Bayes' theorem is used in machine learning to predict outcomes based on prior knowledge and new observations. For example, in spam email detection, Bayes' theorem is used to predict whether an email is spam or not based on the words in the email.\n",
    "\n",
    "Medical diagnosis: Bayes' theorem is used in medical diagnosis to calculate the probability of a patient having a certain disease based on their symptoms and medical history.\n",
    "\n",
    "Weather forecasting: Bayes' theorem is used in weather forecasting to update the probability of weather conditions based on new data and previous observations.\n",
    "\n",
    "Risk analysis: Bayes' theorem is used in risk analysis to calculate the probability of a certain event occurring based on prior knowledge and new information.\n",
    "\n",
    "Finance: Bayes' theorem is used in finance to predict the probability of market movements based on historical data and new information.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c146155-42bd-4193-b5ce-5a0b8eb14cb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q4. What is the relationship between Bayes' theorem and conditional probability?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3da0e8fd-2976-4d74-bc6a-da7c17b685ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Bayes' theorem is based on conditional probability. It is a mathematical formula that calculates the probability of an event occurring, given that another related event has already occurred. Specifically, Bayes' theorem relates the conditional probability of an event A given B, to the conditional probability of event B given A, and the prior probability of A and B.\n",
    "\n",
    "The formula for Bayes' theorem is:\n",
    "\n",
    "P(A|B) = P(B|A) * P(A) / P(B)\n",
    "\n",
    "where:\n",
    "\n",
    "P(A|B) is the posterior probability of event A given that event B has occurred\n",
    "P(B|A) is the conditional probability of event B given that event A has occurred\n",
    "P(A) is the prior probability of event A occurring\n",
    "P(B) is the prior probability of event B occurring\n",
    "Thus, Bayes' theorem allows us to update our prior beliefs about the likelihood of an event A occurring, based on new evidence B. In other words, it allows us to reason probabilistically about cause and effect relationships between events. Bayes' theorem is used in many applications such as medical diagnosis, spam filtering, and text classification.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97064e93-57f0-4408-8e3c-5251c0d906b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q5. How do you choose which type of Naive Bayes classifier to use for any given problem?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3675d0f-f71b-4040-a012-693ee12939de",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Gaussian Naive Bayes: This classifier assumes that the data follows a normal distribution, i.e., continuous variables. It is best suited for problems where the features are continuous variables, and the target variable is categorical, such as spam filtering or sentiment analysis.\n",
    "\n",
    "Multinomial Naive Bayes: This classifier is used when the features are discrete, count-based variables. It is commonly used in natural language processing (NLP) problems, such as text classification or topic modeling, where the features are typically word counts or frequencies.\n",
    "\n",
    "Bernoulli Naive Bayes: This classifier is similar to the multinomial Naive Bayes but is used when the features are binary or Boolean, such as in problems where the presence or absence of a feature is used to predict the target variable.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2103263-66c0-46ae-a958-fcbc3cae0a91",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"You have a dataset with two features, X1 and X2, and two possible classes, A and B. You want to use Naive\n",
    "Bayes to classify a new instance with features X1 = 3 and X2 = 4. The following table shows the frequency of\n",
    "each feature value for each class:\n",
    "Class X1=1 X1=2 X1=3 X2=1 X2=2 X2=3 X2=4\n",
    "A 3 3 4 4 3 3 3\n",
    "B 2 2 1 2 2 2 3\n",
    "Assuming equal prior probabilities for each class, which class would Naive Bayes predict the new instance\n",
    "to belong to?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e83ce85e-d52f-45c6-b9ba-0d34025be539",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "To predict the class of the new instance with Naive Bayes, we need to calculate the posterior probabilities of the two classes A and B, and then choose the class with the highest probability. The formula for the posterior probability of class C given features X1 and X2 is:\n",
    "\n",
    "P(C | X1, X2) = P(X1, X2 | C) * P(C) / P(X1, X2)\n",
    "\n",
    "Since the prior probabilities are equal for both classes, we can ignore the P(C) term in the numerator and denominator and focus on calculating the likelihood P(X1, X2 | C) and the evidence P(X1, X2).\n",
    "\n",
    "For class A:\n",
    "P(X1=3 | A) = 4/10\n",
    "P(X2=4 | A) = 3/10\n",
    "P(X1=3, X2=4 | A) = 2/10\n",
    "\n",
    "For class B:\n",
    "P(X1=3 | B) = 1/7\n",
    "P(X2=4 | B) = 1/7\n",
    "P(X1=3, X2=4 | B) = 1/7\n",
    "\n",
    "To calculate the evidence, we use the law of total probability:\n",
    "P(X1=3, X2=4) = P(X1=3, X2=4 | A) * P(A) + P(X1=3, X2=4 | B) * P(B)\n",
    "= 2/10 * 1/2 + 1/7 * 1/2\n",
    "= 0.15714\n",
    "\n",
    "Now we can substitute the values into the Bayes' theorem formula:\n",
    "P(A | X1=3, X2=4) = P(X1=3, X2=4 | A) * P(A) / P(X1=3, X2=4) = 2/10 * 1/2 / 0.15714 = 0.635\n",
    "P(B | X1=3, X2=4) = P(X1=3, X2=4 | B) * P(B) / P(X1=3, X2=4) = 1/7 * 1/2 / 0.15714 = 0.365\n",
    "\n",
    "Therefore, Naive Bayes would predict the new instance to belong to class A, since it has a higher posterior probability.\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
