{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46ab758c-ab00-49ea-8df1-eae974da4aac",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q1. What is the relationship between polynomial functions and kernel functions in machine learning\n",
    "algorithms?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91ae4b28-9ed2-4be5-abbb-e70f0278cc38",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"In machine learning algorithms, polynomial functions and kernel functions are both used to transform input features into a higher-dimensional space where the problem may become easier to solve. The difference between the two is that polynomial functions are a specific type of kernel function.\n",
    "\n",
    "A kernel function is a function that takes two inputs (vectors) and returns a scalar value that measures the similarity between them. In machine learning, kernel functions are often used in support vector machines (SVMs) to transform input features into a higher-dimensional space where the problem may become easier to solve. The most common types of kernel functions are linear, polynomial, and radial basis function (RBF).\n",
    "\n",
    "A polynomial kernel function is a specific type of kernel function that computes the similarity between two vectors as the polynomial of their dot product. In other words, it maps the input features to a higher-dimensional space where the decision boundary between classes can be a polynomial function.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "200b8d1a-c338-4b31-86f5-ba89fbeb7db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q2. How can we implement an SVM with a polynomial kernel in Python using Scikit-learn?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c1d1fc8-fda0-41ed-9f1b-e38336ce181c",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Load the dataset: Load the dataset using Scikit-learn's built-in datasets or import the dataset from a CSV file.\n",
    "\n",
    "Split the dataset: Split the dataset into a training set and a testing set using Scikit-learn's train_test_split function.\n",
    "\n",
    "Preprocess the data: Preprocess the data by scaling the features using Scikit-learn's StandardScaler function.\n",
    "\n",
    "Create the SVM model: Create an instance of the SVM model using Scikit-learn's SVC (Support Vector Classification) function, and set the kernel parameter to 'poly'.\n",
    "\n",
    "Train the SVM model: Train the SVM model on the training set using the fit method.\n",
    "\n",
    "Test the SVM model: Test the SVM model on the testing set using the predict method.\n",
    "\n",
    "Evaluate the SVM model: Evaluate the performance of the SVM model using Scikit-learn's accuracy_score and classification_report functions.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "60db2e4e-6550-40f8-bcf4-ae2a10cc8031",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q3. How does increasing the value of epsilon affect the number of support vectors in SVR?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3758fff-a0fc-430a-ab0f-50f01a6c243a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"In Support Vector Regression (SVR), epsilon is a hyperparameter that determines the width of the margin around the regression line within which no penalty is given for errors. In other words, it is the distance between the actual target value and the upper/lower bound of the predicted value.\n",
    "\n",
    "Increasing the value of epsilon increases the width of the margin, which leads to fewer support vectors because the model becomes more tolerant to errors and allows more data points to fall outside the margin. This, in turn, reduces the complexity of the model and can lead to faster training and improved generalization performance on unseen data.\n",
    "\n",
    "However, setting epsilon too high can lead to underfitting, where the model is too simplistic and unable to capture the underlying patterns in the data. On the other hand, setting it too low can lead to overfitting, where the model is too complex and captures noise in the data. Therefore, choosing an appropriate value for epsilon is crucial in training an accurate and robust SVR model.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7b62bad-6cf2-42ef-b52a-80f5ec93e54f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Q4. How does the choice of kernel function, C parameter, epsilon parameter, and gamma parameter\n",
    "affect the performance of Support Vector Regression (SVR)? Can you explain how each parameter works\n",
    "and provide examples of when you might want to increase or decrease its value?\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6cdef3bd-1cc8-4a92-b15d-943e045f318a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Kernel function: Kernel functions are used to transform the input data into a higher-dimensional space, where the data can be linearly separable. Popular kernel functions include linear, polynomial, radial basis function (RBF), and sigmoid. The choice of kernel function depends on the nature of the data and the problem at hand. For example, the RBF kernel is suitable for non-linearly separable data, while the linear kernel is appropriate for linearly separable data.\n",
    "\n",
    "C parameter: The C parameter controls the trade-off between achieving a low training error and a low testing error. A small value of C allows for a wider margin, which can lead to more support vectors but a more robust model that is less prone to overfitting. A large value of C leads to a narrower margin, which can reduce the number of support vectors and result in a more complex model that is more prone to overfitting. In general, it is recommended to start with a small value of C and increase it gradually until the desired level of accuracy is achieved.\n",
    "\n",
    "Epsilon parameter: The epsilon parameter determines the width of the margin around the regression line within which no penalty is given for errors. A larger value of epsilon leads to a wider margin, which can reduce the number of support vectors and result in a simpler model. However, setting epsilon too large can lead to underfitting, where the model is too simplistic and unable to capture the underlying patterns in the data.\n",
    "\n",
    "Gamma parameter: The gamma parameter controls the smoothness of the decision boundary. A small value of gamma leads to a smooth decision boundary, while a large value of gamma leads to a more complex and wiggly decision boundary that can fit the training data more closely. However, setting gamma too high can lead to overfitting, where the model is too complex and captures noise in the data.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "66dd7185-28e3-4017-b53d-9198bc77c524",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris\n",
    "\n",
    "iris = load_iris()\n",
    "X = iris.data\n",
    "y = iris.target\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d08ab878-f243-48e3-8ffd-d33e06ecf2a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "78e2bd27-3af7-4958-ac2c-e969d2515d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_train_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "95e20369-92d4-459c-856b-c3930bf82509",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;background-color: white;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=42)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(kernel=&#x27;linear&#x27;, random_state=42)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(kernel='linear', random_state=42)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.svm import SVC\n",
    "\n",
    "svm = SVC(kernel='linear', C=1.0, random_state=42)\n",
    "svm.fit(X_train_scaled, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "043f04f6-79ba-41d7-9a06-6e09f139fa2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = svm.predict(X_test_scaled)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cb812d08-ca8e-4ae0-a0c9-8df480222b0b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.9666666666666667\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "print(\"Accuracy:\", accuracy)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f637f47c-31f3-430e-9e03-704e8d6aea31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best hyperparameters: {'C': 0.1, 'degree': 2, 'gamma': 'auto', 'kernel': 'poly'}\n",
      "Best score: 0.9583333333333334\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "# Create an instance of the SVC classifier\n",
    "svm = SVC()\n",
    "\n",
    "# Define the hyperparameters to tune\n",
    "param_grid = {'C': [0.1, 1, 10],\n",
    "              'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "              'degree': [2, 3, 4],\n",
    "              'gamma': ['scale', 'auto']}\n",
    "\n",
    "# Create an instance of the GridSearchCV object\n",
    "grid_search = GridSearchCV(svm, param_grid, cv=5)\n",
    "\n",
    "# Train the GridSearchCV object on the training data\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Print the best hyperparameters and the corresponding score\n",
    "print(\"Best hyperparameters:\", grid_search.best_params_)\n",
    "print(\"Best score:\", grid_search.best_score_)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "76a46bc5-1323-4e43-a40e-df0f33e1811c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-2 {color: black;background-color: white;}#sk-container-id-2 pre{padding: 0;}#sk-container-id-2 div.sk-toggleable {background-color: white;}#sk-container-id-2 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-2 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-2 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-2 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-2 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-2 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-2 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-2 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-2 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-2 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-2 div.sk-item {position: relative;z-index: 1;}#sk-container-id-2 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-2 div.sk-item::before, #sk-container-id-2 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-2 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-2 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-2 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-2 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-2 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-2 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-2 div.sk-label-container {text-align: center;}#sk-container-id-2 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-2 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-2\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>SVC(C=1, gamma=0.1)</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-2\" type=\"checkbox\" checked><label for=\"sk-estimator-id-2\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">SVC</label><div class=\"sk-toggleable__content\"><pre>SVC(C=1, gamma=0.1)</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "SVC(C=1, gamma=0.1)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# concatenate the original training and testing datasets\n",
    "X = np.concatenate((X_train, X_test))\n",
    "y = np.concatenate((y_train, y_test))\n",
    "\n",
    "# preprocess the data using standard scaling\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X)\n",
    "\n",
    "# instantiate the tuned SVC classifier\n",
    "tuned_svc = SVC(C=1, gamma=0.1, kernel='rbf')\n",
    "\n",
    "# train the tuned SVC classifier on the preprocessed data\n",
    "tuned_svc.fit(X_scaled, y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "39b855d4-f283-4257-9c77-147aab016287",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "\n",
    "# train the tuned classifier on the entire dataset\n",
    "tuned_svc.fit(X, y)\n",
    "\n",
    "# save the trained classifier to a file\n",
    "with open('svm_classifier.pkl', 'wb') as f:\n",
    "    pickle.dump(tuned_svc, f)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c564af2f-6b5c-4972-9198-ce5a9e19fabb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
